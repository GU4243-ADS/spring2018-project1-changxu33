---
output:
  word_document: default
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(topicmodels)
library(RColorBrewer)
library(wordcloud)
library(ggridges)
library(igraph)
library(ggraph)
library(sentimentr)
library(syuzhet)
library(broom)
library(urltools)
library(exploratory)
library(ldatuning)
library(purrr)
library(CTM)
library(stm)
library(corpus)
library(tm)
library(quanteda)
source("../libs/multiplot.R")
spooky<-read.csv('../data/spooky.csv',as.is=T)
spooky_wrd<-unnest_tokens(spooky,word,text)

bigrams<-unnest_tokens(spooky,bigram, text, token = "ngrams", n = 2)
bigrams_HPL<-unnest_tokens(spooky[spooky$author=='HPL',],bigram, text, token = "ngrams", n = 2)
head(bigrams_HPL)
bigrams_MWS<-unnest_tokens(spooky[spooky$author=='MWS',],bigram, text, token = "ngrams", n = 2)
head(bigrams_MWS)
bigrams_EAP<-unnest_tokens(spooky[spooky$author=='EAP',],bigram, text, token = "ngrams", n = 2)
head(bigrams_EAP)

bigrams_separated<-separate(bigrams,bigram,c("word1", "word2"),sep = " ")
bigrams_filtered<-bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
bigrams_united<-bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")
AFINN<-get_sentiments("afinn")
```
We then use spread() so that we have negative and positive sentiment in separate columns, and lastly calculate a net sentiment (positive - negative).
And Now we can plot these sentiment scores across the plot trajectory of each author. Notice that we are plotting against the index on the x-axis that keeps track of text.
```{r}
head(spooky_wrd)
specialsentiment<-spooky_wrd%>%inner_join(get_sentiments("bing")) %>%
  count(index=id, author, sentiment)%>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
specialsentiment_300<-head(specialsentiment,300)

ggplot(specialsentiment_300, aes(index , sentiment, fill = author)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~author, ncol = 2, scales = "free_x")+
  coord_flip()
```
We can see how the plot of each author changes toward more positive or negative sentiment over the trajectory of the story.

###4: Comparing the three sentiment dictionaries

With several options for sentiment lexicons, you might want some more information on which one is appropriate for your purposes. Let’s use all three sentiment lexicons and examine how the sentiment changes across the author.
```{r}
afinn_method<-spooky_wrd%>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index =id) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")
afinn_300<-head(afinn_method,300)
bing_method<-spooky_wrd%>% 
  inner_join(get_sentiments("bing")) %>%
  mutate(method = "Bing et al.") %>%
  count(method, index =id, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
bing_300<-head(bing_method,300)
nrc_method<-spooky_wrd%>%
  inner_join(get_sentiments("nrc") %>%
               filter(sentiment %in% c("positive","negative"))%>%
               mutate(method = "NRC")) %>%
  count(method, index =id, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
nrc_300<-head(nrc_method,300)
```

We now have an estimate of the net sentiment (positive - negative) in each chunk of the text for each sentiment lexicon. Let’s bind them together and visualize them. 
```{r}
bind_rows(afinn_300, 
          bing_300, nrc_300) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

The three different lexicons for calculating sentiment give results that are different in an absolute sense but have similar relative trajectories through the author. We see similar dips and peaks in sentiment at about the same places in the author, but the absolute values are significantly different. The AFINN lexicon gives the largest absolute values, with high positive values. The lexicon from Bing et al. has lower absolute values and seems to label larger blocks of contiguous positive or negative text. The NRC results are shifted higher relative to the other two, labeling the text more positively, but detects similar relative changes in the text. Sentiment appears to find longer stretches of similar text, but all three agree roughly on the overall trends in the sentiment through a narrative arc.

