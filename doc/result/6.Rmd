---
output:
  word_document: default
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(topicmodels)
library(RColorBrewer)
library(wordcloud)
library(ggridges)
library(igraph)
library(ggraph)
library(sentimentr)
library(syuzhet)
library(broom)
library(urltools)
library(exploratory)
library(ldatuning)
library(purrr)
library(CTM)
library(stm)
library(corpus)
library(tm)
library(quanteda)
source("../libs/multiplot.R")
spooky<-read.csv('../data/spooky.csv',as.is=T)
bigrams<-unnest_tokens(spooky,bigram, text, token = "ngrams", n = 2)
bigrams_HPL<-unnest_tokens(spooky[spooky$author=='HPL',],bigram, text, token = "ngrams", n = 2)
head(bigrams_HPL)
bigrams_MWS<-unnest_tokens(spooky[spooky$author=='MWS',],bigram, text, token = "ngrams", n = 2)
head(bigrams_MWS)
bigrams_EAP<-unnest_tokens(spooky[spooky$author=='EAP',],bigram, text, token = "ngrams", n = 2)
head(bigrams_EAP)
```

```{r}
bigrams_separated<-separate(bigrams,bigram,c("word1", "word2"),sep = " ")
bigrams_filtered<-bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts<-bigrams_filtered %>% 
  count(word1,word2,sort=T)
head(bigram_counts)

bigrams_HPL_separated<-separate(bigrams_HPL,bigram,c("word1", "word2"),sep = " ")
bigrams_HPL_filtered<-bigrams_HPL_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_HPL_counts<-bigrams_HPL_filtered %>% 
  count(word1,word2,sort=T)
head(bigram_HPL_counts)

bigrams_MWS_separated<-separate(bigrams_MWS,bigram,c("word1", "word2"),sep = " ")
bigrams_MWS_filtered<-bigrams_MWS_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_MWS_counts<-bigrams_MWS_filtered %>% 
  count(word1,word2,sort=T)
head(bigram_MWS_counts)

bigrams_EAP_separated<-separate(bigrams_EAP,bigram,c("word1", "word2"),sep = " ")
bigrams_EAP_filtered<-bigrams_EAP_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_EAP_counts<-bigrams_EAP_filtered %>% 
  count(word1,word2,sort=T)
head(bigram_EAP_counts)
```
We can see that these phrases are the most common pairs in spooky data set.

In other analyses, we may want to work with the recombined words. tidyr’s unite() function is the inverse of separate(), and lets us recombine the columns into one. Thus, “separate/filter/count/unite” let us find the most common bigrams not containing stop-words.
```{r}
bigrams_united<-bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")
head(bigrams_united)
```
