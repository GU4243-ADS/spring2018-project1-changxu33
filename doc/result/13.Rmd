---
output:
  word_document: default
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(topicmodels)
library(RColorBrewer)
library(wordcloud)
library(ggridges)
library(igraph)
library(ggraph)
library(sentimentr)
library(syuzhet)
library(broom)
library(urltools)
library(exploratory)
library(ldatuning)
library(purrr)
library(CTM)
library(stm)
library(corpus)
library(tm)
library(quanteda)
source("../libs/multiplot.R")
spooky<-read.csv('../data/spooky.csv',as.is=T)
spooky_wrd<-unnest_tokens(spooky,word,text)
AFINN<-get_sentiments("afinn")
sent_wrd_freqs <- count(spooky_wrd, id, word)
spooky_wrd_tm <- cast_dtm(sent_wrd_freqs, id, word, n)
spooky_wrd_lda_6<-LDA(spooky_wrd_tm,k=6, control = list(seed = 1234))
```
##step2: Visualizing author topics

```{r}
spooky_wrd_docs <- tidy(spooky_wrd_lda_6, matrix = "gamma")
head(spooky_wrd_docs)
author_topics <- left_join(spooky_wrd_docs, spooky, by = c("document" = "id"))
author_topics <- select(author_topics, -text)
author_topics$topic <- as.factor(author_topics$topic)
# Chooses the top topic per sentence
author_topics <- ungroup(top_n(group_by(author_topics, document), 1, gamma))

# Counts the number of sentences represented by each topic per author 
author_topics <- ungroup(count(group_by(author_topics, author, topic)))
author_topics
ggplot(author_topics) +
  geom_col(aes(topic, n, fill = factor(topic)), show.legend = FALSE) +
  facet_wrap(~ author, scales = "free", ncol = 4) +
  coord_flip()
```
From plot, we learn different author focus on diffrernt topics. And combine 5 top words for each topics, we can get theme for each author.

# Section 5:Summary


